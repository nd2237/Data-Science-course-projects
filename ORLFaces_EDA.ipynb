{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a98468ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55de137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#資料路徑\n",
    "folder = '/Users/nuo/Documents/DA/HW2/ORL Faces'\n",
    "\n",
    "#判斷性別\n",
    "def gender(g):\n",
    "    if g in [1, 8, 10, 32]:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "#讀檔、建立矩陣\n",
    "def order():\n",
    "    pic = []\n",
    "    gender_list = []\n",
    "    #按照順序讀取圖片\n",
    "    for i in range(1, 41):\n",
    "        for j in range(1, 11):\n",
    "            img = cv2.imread(folder + '/' + str(i) + '_' + str(j) + '.png', 0)\n",
    "            pic.append(img)\n",
    "            gender_list.append(gender(i))      \n",
    "    #將性別資料加入原先矩陣中     \n",
    "    arr = np.array(pic)\n",
    "    arr = arr.reshape(400, 2576)\n",
    "    arr = pd.DataFrame(arr)\n",
    "    arr['gender'] = [g for g in gender_list]   \n",
    "    return arr\n",
    "\n",
    "#輸出結果\n",
    "result = order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af08a66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2567</th>\n",
       "      <th>2568</th>\n",
       "      <th>2569</th>\n",
       "      <th>2570</th>\n",
       "      <th>2571</th>\n",
       "      <th>2572</th>\n",
       "      <th>2573</th>\n",
       "      <th>2574</th>\n",
       "      <th>2575</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>99</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>176</td>\n",
       "      <td>166</td>\n",
       "      <td>149</td>\n",
       "      <td>142</td>\n",
       "      <td>145</td>\n",
       "      <td>141</td>\n",
       "      <td>138</td>\n",
       "      <td>142</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>97</td>\n",
       "      <td>107</td>\n",
       "      <td>111</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>175</td>\n",
       "      <td>172</td>\n",
       "      <td>147</td>\n",
       "      <td>131</td>\n",
       "      <td>132</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>120</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>88</td>\n",
       "      <td>98</td>\n",
       "      <td>104</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>128</td>\n",
       "      <td>154</td>\n",
       "      <td>161</td>\n",
       "      <td>169</td>\n",
       "      <td>170</td>\n",
       "      <td>165</td>\n",
       "      <td>146</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92</td>\n",
       "      <td>96</td>\n",
       "      <td>93</td>\n",
       "      <td>94</td>\n",
       "      <td>99</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>109</td>\n",
       "      <td>121</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>153</td>\n",
       "      <td>164</td>\n",
       "      <td>163</td>\n",
       "      <td>165</td>\n",
       "      <td>166</td>\n",
       "      <td>161</td>\n",
       "      <td>157</td>\n",
       "      <td>79</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>75</td>\n",
       "      <td>88</td>\n",
       "      <td>91</td>\n",
       "      <td>101</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>80</td>\n",
       "      <td>63</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>145</td>\n",
       "      <td>148</td>\n",
       "      <td>151</td>\n",
       "      <td>139</td>\n",
       "      <td>134</td>\n",
       "      <td>173</td>\n",
       "      <td>167</td>\n",
       "      <td>176</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>63</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>129</td>\n",
       "      <td>128</td>\n",
       "      <td>129</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>122</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>126</td>\n",
       "      <td>130</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>120</td>\n",
       "      <td>119</td>\n",
       "      <td>121</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>121</td>\n",
       "      <td>122</td>\n",
       "      <td>117</td>\n",
       "      <td>111</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>134</td>\n",
       "      <td>101</td>\n",
       "      <td>26</td>\n",
       "      <td>77</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>69</td>\n",
       "      <td>55</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2577 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9  ...  2567  2568  2569  \\\n",
       "0     88   88   90   91   91   92   90   93   99  109  ...   176   166   149   \n",
       "1     87   90   95   96   92   90   97  107  111  112  ...   175   172   147   \n",
       "2     92   92   88   98  104  109  108  100   80   63  ...    84   128   154   \n",
       "3     92   96   93   94   99  105  108  109  121  152  ...   153   164   163   \n",
       "4     83   75   88   91  101   90   86   80   63   58  ...   145   148   151   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   \n",
       "395  124  124  125  123  124  125  123  124  123  122  ...    34    63    37   \n",
       "396  128  128  128  128  129  128  129  127  127  127  ...    92    90    90   \n",
       "397  122  123  124  124  123  123  122  126  130  126  ...    24    57    41   \n",
       "398  120  119  121  119  120  121  122  117  111  100  ...   137   134   101   \n",
       "399  124  125  125  125  124  125  124  124  124  124  ...    35    69    55   \n",
       "\n",
       "     2570  2571  2572  2573  2574  2575  gender  \n",
       "0     142   145   141   138   142   134       0  \n",
       "1     131   132   124   124   120    88       0  \n",
       "2     161   169   170   165   146   151       0  \n",
       "3     165   166   161   157    79    54       0  \n",
       "4     139   134   173   167   176   188       0  \n",
       "..    ...   ...   ...   ...   ...   ...     ...  \n",
       "395    37    37    38    39    38    40       1  \n",
       "396    91    91    91    91    92    93       1  \n",
       "397    37    36    37    38    40    38       1  \n",
       "398    26    77    95    95    92    90       1  \n",
       "399    31    36    33    33    34    34       1  \n",
       "\n",
       "[400 rows x 2577 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82510c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2566</th>\n",
       "      <th>2567</th>\n",
       "      <th>2568</th>\n",
       "      <th>2569</th>\n",
       "      <th>2570</th>\n",
       "      <th>2571</th>\n",
       "      <th>2572</th>\n",
       "      <th>2573</th>\n",
       "      <th>2574</th>\n",
       "      <th>2575</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>99</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>168</td>\n",
       "      <td>176</td>\n",
       "      <td>166</td>\n",
       "      <td>149</td>\n",
       "      <td>142</td>\n",
       "      <td>145</td>\n",
       "      <td>141</td>\n",
       "      <td>138</td>\n",
       "      <td>142</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>97</td>\n",
       "      <td>107</td>\n",
       "      <td>111</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>167</td>\n",
       "      <td>175</td>\n",
       "      <td>172</td>\n",
       "      <td>147</td>\n",
       "      <td>131</td>\n",
       "      <td>132</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>120</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>88</td>\n",
       "      <td>98</td>\n",
       "      <td>104</td>\n",
       "      <td>109</td>\n",
       "      <td>108</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>111</td>\n",
       "      <td>84</td>\n",
       "      <td>128</td>\n",
       "      <td>154</td>\n",
       "      <td>161</td>\n",
       "      <td>169</td>\n",
       "      <td>170</td>\n",
       "      <td>165</td>\n",
       "      <td>146</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92</td>\n",
       "      <td>96</td>\n",
       "      <td>93</td>\n",
       "      <td>94</td>\n",
       "      <td>99</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>109</td>\n",
       "      <td>121</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>154</td>\n",
       "      <td>153</td>\n",
       "      <td>164</td>\n",
       "      <td>163</td>\n",
       "      <td>165</td>\n",
       "      <td>166</td>\n",
       "      <td>161</td>\n",
       "      <td>157</td>\n",
       "      <td>79</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>75</td>\n",
       "      <td>88</td>\n",
       "      <td>91</td>\n",
       "      <td>101</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>80</td>\n",
       "      <td>63</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>141</td>\n",
       "      <td>145</td>\n",
       "      <td>148</td>\n",
       "      <td>151</td>\n",
       "      <td>139</td>\n",
       "      <td>134</td>\n",
       "      <td>173</td>\n",
       "      <td>167</td>\n",
       "      <td>176</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>34</td>\n",
       "      <td>63</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>129</td>\n",
       "      <td>128</td>\n",
       "      <td>129</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>122</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>126</td>\n",
       "      <td>130</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>120</td>\n",
       "      <td>119</td>\n",
       "      <td>121</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>121</td>\n",
       "      <td>122</td>\n",
       "      <td>117</td>\n",
       "      <td>111</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>146</td>\n",
       "      <td>137</td>\n",
       "      <td>134</td>\n",
       "      <td>101</td>\n",
       "      <td>26</td>\n",
       "      <td>77</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>69</td>\n",
       "      <td>55</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 2576 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4     5     6     7     8     9     ...  2566  \\\n",
       "0      88    88    90    91    91    92    90    93    99   109  ...   168   \n",
       "1      87    90    95    96    92    90    97   107   111   112  ...   167   \n",
       "2      92    92    88    98   104   109   108   100    80    63  ...   111   \n",
       "3      92    96    93    94    99   105   108   109   121   152  ...   154   \n",
       "4      83    75    88    91   101    90    86    80    63    58  ...   141   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "395   124   124   125   123   124   125   123   124   123   122  ...    57   \n",
       "396   128   128   128   128   129   128   129   127   127   127  ...    96   \n",
       "397   122   123   124   124   123   123   122   126   130   126  ...    68   \n",
       "398   120   119   121   119   120   121   122   117   111   100  ...   146   \n",
       "399   124   125   125   125   124   125   124   124   124   124  ...    23   \n",
       "\n",
       "     2567  2568  2569  2570  2571  2572  2573  2574  2575  \n",
       "0     176   166   149   142   145   141   138   142   134  \n",
       "1     175   172   147   131   132   124   124   120    88  \n",
       "2      84   128   154   161   169   170   165   146   151  \n",
       "3     153   164   163   165   166   161   157    79    54  \n",
       "4     145   148   151   139   134   173   167   176   188  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "395    34    63    37    37    37    38    39    38    40  \n",
       "396    92    90    90    91    91    91    91    92    93  \n",
       "397    24    57    41    37    36    37    38    40    38  \n",
       "398   137   134   101    26    77    95    95    92    90  \n",
       "399    35    69    55    31    36    33    33    34    34  \n",
       "\n",
       "[400 rows x 2576 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = result.drop(columns = 'gender')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f86125f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#標準化\n",
    "# scaler = StandardScaler()\n",
    "# data = scaler.fit_transform(data)\n",
    "# data = pd.DataFrame(data)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a92beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = result['gender']\n",
    "x = data\n",
    "#x, y = np.array(data), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37dc7008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearRegression Model\n",
    "model = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4117eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Sequential Feature Selector\n",
    "# #定義SFS，最終希望變成50個feature，direction沒設代表default forward\n",
    "# sfs = SequentialFeatureSelector(model, n_features_to_select=50)\n",
    "# #學習feature selection\n",
    "# sfs.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57216881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>41</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>56</th>\n",
       "      <th>89</th>\n",
       "      <th>154</th>\n",
       "      <th>156</th>\n",
       "      <th>183</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>...</th>\n",
       "      <th>2310</th>\n",
       "      <th>2419</th>\n",
       "      <th>2438</th>\n",
       "      <th>2470</th>\n",
       "      <th>2485</th>\n",
       "      <th>2528</th>\n",
       "      <th>2539</th>\n",
       "      <th>2540</th>\n",
       "      <th>2546</th>\n",
       "      <th>2574</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "      <td>175</td>\n",
       "      <td>87</td>\n",
       "      <td>88</td>\n",
       "      <td>105</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>113</td>\n",
       "      <td>103</td>\n",
       "      <td>78</td>\n",
       "      <td>112</td>\n",
       "      <td>114</td>\n",
       "      <td>102</td>\n",
       "      <td>135</td>\n",
       "      <td>124</td>\n",
       "      <td>82</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>138</td>\n",
       "      <td>133</td>\n",
       "      <td>144</td>\n",
       "      <td>136</td>\n",
       "      <td>127</td>\n",
       "      <td>98</td>\n",
       "      <td>130</td>\n",
       "      <td>102</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>146</td>\n",
       "      <td>112</td>\n",
       "      <td>198</td>\n",
       "      <td>91</td>\n",
       "      <td>211</td>\n",
       "      <td>80</td>\n",
       "      <td>111</td>\n",
       "      <td>101</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140</td>\n",
       "      <td>149</td>\n",
       "      <td>142</td>\n",
       "      <td>65</td>\n",
       "      <td>145</td>\n",
       "      <td>79</td>\n",
       "      <td>66</td>\n",
       "      <td>134</td>\n",
       "      <td>71</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>107</td>\n",
       "      <td>78</td>\n",
       "      <td>150</td>\n",
       "      <td>206</td>\n",
       "      <td>195</td>\n",
       "      <td>86</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123</td>\n",
       "      <td>93</td>\n",
       "      <td>86</td>\n",
       "      <td>165</td>\n",
       "      <td>115</td>\n",
       "      <td>98</td>\n",
       "      <td>86</td>\n",
       "      <td>106</td>\n",
       "      <td>94</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>95</td>\n",
       "      <td>200</td>\n",
       "      <td>157</td>\n",
       "      <td>205</td>\n",
       "      <td>55</td>\n",
       "      <td>130</td>\n",
       "      <td>124</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139</td>\n",
       "      <td>151</td>\n",
       "      <td>162</td>\n",
       "      <td>58</td>\n",
       "      <td>152</td>\n",
       "      <td>71</td>\n",
       "      <td>79</td>\n",
       "      <td>133</td>\n",
       "      <td>75</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>80</td>\n",
       "      <td>50</td>\n",
       "      <td>133</td>\n",
       "      <td>52</td>\n",
       "      <td>166</td>\n",
       "      <td>125</td>\n",
       "      <td>155</td>\n",
       "      <td>57</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>119</td>\n",
       "      <td>118</td>\n",
       "      <td>119</td>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "      <td>92</td>\n",
       "      <td>87</td>\n",
       "      <td>118</td>\n",
       "      <td>92</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>133</td>\n",
       "      <td>174</td>\n",
       "      <td>91</td>\n",
       "      <td>78</td>\n",
       "      <td>91</td>\n",
       "      <td>37</td>\n",
       "      <td>102</td>\n",
       "      <td>137</td>\n",
       "      <td>64</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>123</td>\n",
       "      <td>138</td>\n",
       "      <td>124</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>124</td>\n",
       "      <td>87</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>159</td>\n",
       "      <td>123</td>\n",
       "      <td>71</td>\n",
       "      <td>131</td>\n",
       "      <td>70</td>\n",
       "      <td>91</td>\n",
       "      <td>105</td>\n",
       "      <td>94</td>\n",
       "      <td>55</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>119</td>\n",
       "      <td>125</td>\n",
       "      <td>121</td>\n",
       "      <td>100</td>\n",
       "      <td>91</td>\n",
       "      <td>119</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>177</td>\n",
       "      <td>88</td>\n",
       "      <td>97</td>\n",
       "      <td>88</td>\n",
       "      <td>40</td>\n",
       "      <td>121</td>\n",
       "      <td>130</td>\n",
       "      <td>81</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>77</td>\n",
       "      <td>126</td>\n",
       "      <td>169</td>\n",
       "      <td>139</td>\n",
       "      <td>124</td>\n",
       "      <td>109</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>84</td>\n",
       "      <td>63</td>\n",
       "      <td>141</td>\n",
       "      <td>62</td>\n",
       "      <td>92</td>\n",
       "      <td>63</td>\n",
       "      <td>28</td>\n",
       "      <td>48</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>116</td>\n",
       "      <td>118</td>\n",
       "      <td>115</td>\n",
       "      <td>123</td>\n",
       "      <td>118</td>\n",
       "      <td>104</td>\n",
       "      <td>124</td>\n",
       "      <td>116</td>\n",
       "      <td>86</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>149</td>\n",
       "      <td>69</td>\n",
       "      <td>94</td>\n",
       "      <td>89</td>\n",
       "      <td>93</td>\n",
       "      <td>34</td>\n",
       "      <td>48</td>\n",
       "      <td>128</td>\n",
       "      <td>56</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     41    44    45    56    89    154   156   183   201   202   ...  2310  \\\n",
       "0      87    85    86   175    87    88   105    90    60    67  ...   113   \n",
       "1     128   138   133   144   136   127    98   130   102    98  ...   146   \n",
       "2     140   149   142    65   145    79    66   134    71    60  ...    94   \n",
       "3     123    93    86   165   115    98    86   106    94    87  ...    99   \n",
       "4     139   151   162    58   152    71    79   133    75    88  ...    52   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "395   119   118   119   130   120    92    87   118    92    81  ...   133   \n",
       "396   124   124   123   138   124    73    73   124    87    85  ...   159   \n",
       "397   121   121   119   125   121   100    91   119   102    96  ...   119   \n",
       "398   126   126   126    77   126   169   139   124   109   110  ...    63   \n",
       "399   116   118   115   123   118   104   124   116    86    88  ...   149   \n",
       "\n",
       "     2419  2438  2470  2485  2528  2539  2540  2546  2574  \n",
       "0     103    78   112   114   102   135   124    82   142  \n",
       "1     112   198    91   211    80   111   101    90   120  \n",
       "2      76    75   107    78   150   206   195    86   146  \n",
       "3      95   200   157   205    55   130   124    79    79  \n",
       "4      80    50   133    52   166   125   155    57   176  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "395   174    91    78    91    37   102   137    64    38  \n",
       "396   123    71   131    70    91   105    94    55    92  \n",
       "397   177    88    97    88    40   121   130    81    40  \n",
       "398    84    63   141    62    92    63    28    48    92  \n",
       "399    69    94    89    93    34    48   128    56    34  \n",
       "\n",
       "[400 rows x 111 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "val = []\n",
    "for i in range(len(model.coef_)):\n",
    "    if abs(model.coef_[i]) > 0.0002:\n",
    "        val.append(i)\n",
    "f = data[val]\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b606db4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 gender   R-squared (uncentered):                   0.982\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.975\n",
      "Method:                 Least Squares   F-statistic:                              141.1\n",
      "Date:                Sun, 12 Mar 2023   Prob (F-statistic):                   2.54e-203\n",
      "Time:                        21:48:55   Log-Likelihood:                          255.67\n",
      "No. Observations:                 400   AIC:                                     -289.3\n",
      "Df Residuals:                     289   BIC:                                      153.7\n",
      "Df Model:                         111                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "41            -0.0016      0.002     -0.680      0.497      -0.006       0.003\n",
      "44         -3.378e-05      0.005     -0.007      0.994      -0.009       0.009\n",
      "45             0.0003      0.004      0.068      0.946      -0.007       0.008\n",
      "56            -0.0013      0.000     -2.644      0.009      -0.002      -0.000\n",
      "89            -0.0017      0.003     -0.473      0.636      -0.009       0.005\n",
      "154           -0.0002      0.001     -0.282      0.778      -0.002       0.001\n",
      "156            0.0003      0.001      0.324      0.746      -0.001       0.002\n",
      "183           -0.0007      0.004     -0.182      0.856      -0.008       0.007\n",
      "201            0.0006      0.001      0.488      0.626      -0.002       0.003\n",
      "202            0.0016      0.001      1.444      0.150      -0.001       0.004\n",
      "324            0.0017      0.001      1.766      0.078      -0.000       0.004\n",
      "370            0.0002      0.001      0.254      0.800      -0.002       0.002\n",
      "439           -0.0015      0.001     -1.248      0.213      -0.004       0.001\n",
      "440         -9.59e-05      0.001     -0.078      0.938      -0.003       0.002\n",
      "464            0.0006      0.001      0.774      0.440      -0.001       0.002\n",
      "486           -0.0002      0.001     -0.297      0.767      -0.002       0.001\n",
      "493            0.0016      0.001      1.690      0.092      -0.000       0.003\n",
      "494         4.197e-05      0.001      0.046      0.963      -0.002       0.002\n",
      "509           -0.0016      0.001     -1.435      0.152      -0.004       0.001\n",
      "554           -0.0002      0.001     -0.175      0.861      -0.003       0.002\n",
      "600           -0.0003      0.001     -0.275      0.784      -0.002       0.002\n",
      "647           -0.0015      0.001     -1.279      0.202      -0.004       0.001\n",
      "648            0.0002      0.001      0.401      0.689      -0.001       0.001\n",
      "693            0.0014      0.001      1.302      0.194      -0.001       0.004\n",
      "869            0.0011      0.001      1.109      0.268      -0.001       0.003\n",
      "873            0.0001      0.000      0.349      0.727      -0.001       0.001\n",
      "915           -0.0019      0.001     -1.857      0.064      -0.004       0.000\n",
      "939            0.0002      0.000      0.571      0.568      -0.001       0.001\n",
      "969            0.0011      0.000      2.701      0.007       0.000       0.002\n",
      "976            0.0009      0.000      2.287      0.023       0.000       0.002\n",
      "995           -0.0007      0.000     -1.713      0.088      -0.002       0.000\n",
      "1003       -9.495e-05      0.001     -0.157      0.875      -0.001       0.001\n",
      "1004          -0.0007      0.001     -0.984      0.326      -0.002       0.001\n",
      "1046           0.0012      0.000      2.492      0.013       0.000       0.002\n",
      "1050          -0.0001      0.001     -0.181      0.857      -0.001       0.001\n",
      "1062          -0.0010      0.000     -2.698      0.007      -0.002      -0.000\n",
      "1069          -0.0010      0.000     -2.707      0.007      -0.002      -0.000\n",
      "1084          -0.0004      0.000     -0.871      0.384      -0.001       0.000\n",
      "1094           0.0004      0.000      0.773      0.440      -0.001       0.001\n",
      "1105       -5.034e-05      0.001     -0.092      0.927      -0.001       0.001\n",
      "1122           0.0008      0.001      1.585      0.114      -0.000       0.002\n",
      "1151          -0.0003      0.001     -0.467      0.641      -0.001       0.001\n",
      "1167          -0.0014      0.001     -2.243      0.026      -0.003      -0.000\n",
      "1168          -0.0004      0.001     -0.567      0.571      -0.002       0.001\n",
      "1177          -0.0011      0.000     -2.486      0.013      -0.002      -0.000\n",
      "1179           0.0001      0.000      0.246      0.806      -0.001       0.001\n",
      "1184          -0.0001      0.001     -0.279      0.780      -0.001       0.001\n",
      "1187          -0.0007      0.000     -1.496      0.136      -0.002       0.000\n",
      "1209        3.112e-05      0.000      0.063      0.949      -0.001       0.001\n",
      "1213        4.208e-05      0.001      0.079      0.937      -0.001       0.001\n",
      "1230          -0.0003      0.001     -0.561      0.575      -0.001       0.001\n",
      "1232           0.0003      0.000      0.580      0.562      -0.001       0.001\n",
      "1255          -0.0003      0.000     -0.693      0.489      -0.001       0.001\n",
      "1291       -7.077e-05      0.000     -0.195      0.845      -0.001       0.001\n",
      "1323           0.0013      0.001      2.412      0.016       0.000       0.002\n",
      "1367           0.0012      0.001      2.308      0.022       0.000       0.002\n",
      "1387          -0.0004      0.000     -0.803      0.422      -0.001       0.001\n",
      "1417           0.0016      0.000      3.196      0.002       0.001       0.003\n",
      "1427           0.0012      0.000      3.262      0.001       0.000       0.002\n",
      "1446          -0.0012      0.000     -3.517      0.001      -0.002      -0.001\n",
      "1518           0.0003      0.001      0.434      0.665      -0.001       0.002\n",
      "1564           0.0011      0.001      1.613      0.108      -0.000       0.003\n",
      "1574          -0.0003      0.001     -0.470      0.639      -0.002       0.001\n",
      "1613           0.0002      0.000      0.428      0.669      -0.001       0.001\n",
      "1614           0.0006      0.000      1.328      0.185      -0.000       0.001\n",
      "1628           0.0006      0.000      1.554      0.121      -0.000       0.001\n",
      "1681           0.0012      0.000      3.420      0.001       0.001       0.002\n",
      "1712           0.0013      0.001      1.229      0.220      -0.001       0.003\n",
      "1730           0.0022      0.000      5.558      0.000       0.001       0.003\n",
      "1758          -0.0005      0.001     -0.558      0.577      -0.002       0.001\n",
      "1789           0.0015      0.001      2.499      0.013       0.000       0.003\n",
      "1796           0.0005      0.001      0.647      0.518      -0.001       0.002\n",
      "1835          -0.0012      0.001     -2.092      0.037      -0.002   -7.28e-05\n",
      "1842          -0.0013      0.001     -1.290      0.198      -0.003       0.001\n",
      "1845          -0.0015      0.001     -2.302      0.022      -0.003      -0.000\n",
      "1864          -0.0001      0.000     -0.431      0.666      -0.001       0.001\n",
      "1878          -0.0002      0.001     -0.259      0.796      -0.002       0.001\n",
      "1891           0.0020      0.001      2.441      0.015       0.000       0.004\n",
      "1902           0.0009      0.000      2.688      0.008       0.000       0.002\n",
      "1924          -0.0013      0.001     -1.853      0.065      -0.003    8.01e-05\n",
      "1930           0.0006      0.001      0.846      0.398      -0.001       0.002\n",
      "1934          -0.0018      0.001     -2.189      0.029      -0.003      -0.000\n",
      "1935          -0.0006      0.001     -0.794      0.428      -0.002       0.001\n",
      "1983          -0.0015      0.001     -1.479      0.140      -0.004       0.001\n",
      "2029          -0.0002      0.001     -0.198      0.843      -0.002       0.002\n",
      "2030          -0.0017      0.001     -2.691      0.008      -0.003      -0.000\n",
      "2045           0.0011      0.001      1.247      0.214      -0.001       0.003\n",
      "2046          -0.0002      0.001     -0.262      0.794      -0.002       0.001\n",
      "2066           0.0005      0.001      0.624      0.533      -0.001       0.002\n",
      "2073           0.0018      0.001      2.836      0.005       0.001       0.003\n",
      "2116           0.0033      0.001      3.407      0.001       0.001       0.005\n",
      "2142           0.0006      0.000      1.352      0.177      -0.000       0.002\n",
      "2162           0.0014      0.001      1.584      0.114      -0.000       0.003\n",
      "2167           0.0015      0.001      1.767      0.078      -0.000       0.003\n",
      "2213           0.0003      0.001      0.341      0.733      -0.001       0.002\n",
      "2258          -0.0003      0.001     -0.598      0.550      -0.001       0.001\n",
      "2261          -0.0005      0.001     -0.711      0.477      -0.002       0.001\n",
      "2264           0.0004      0.001      0.483      0.629      -0.001       0.002\n",
      "2274          -0.0016      0.000     -3.892      0.000      -0.002      -0.001\n",
      "2303           0.0004      0.001      0.751      0.453      -0.001       0.001\n",
      "2307           0.0007      0.001      1.118      0.265      -0.001       0.002\n",
      "2310           0.0003      0.001      0.465      0.643      -0.001       0.002\n",
      "2419           0.0018      0.000      4.349      0.000       0.001       0.003\n",
      "2438           0.0011      0.000      2.925      0.004       0.000       0.002\n",
      "2470          -0.0009      0.000     -2.343      0.020      -0.002      -0.000\n",
      "2485           0.0012      0.000      3.231      0.001       0.000       0.002\n",
      "2528          -0.0005      0.001     -0.668      0.505      -0.002       0.001\n",
      "2539       -4.073e-05      0.000     -0.120      0.905      -0.001       0.001\n",
      "2540          -0.0013      0.000     -3.443      0.001      -0.002      -0.001\n",
      "2546          -0.0010      0.000     -2.377      0.018      -0.002      -0.000\n",
      "2574           0.0005      0.001      0.819      0.413      -0.001       0.002\n",
      "==============================================================================\n",
      "Omnibus:                        2.690   Durbin-Watson:                   1.525\n",
      "Prob(Omnibus):                  0.261   Jarque-Bera (JB):                2.435\n",
      "Skew:                          -0.156   Prob(JB):                        0.296\n",
      "Kurtosis:                       3.221   Cond. No.                         869.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#stepwise 1\n",
    "StatsModel = sm.OLS(y, f).fit()\n",
    "print(StatsModel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bdff27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = StatsModel.pvalues\n",
    "s = pd.DataFrame(s)\n",
    "s['pvalue'] = s[0]\n",
    "s = s.reset_index()\n",
    "s = s.drop(0, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9da41d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56, 969, 976, 1046, 1062, 1069, 1167, 1177, 1323, 1367, 1417, 1427, 1446, 1681, 1730, 1789, 1835, 1845, 1891, 1902, 1934, 2030, 2073, 2116, 2274, 2419, 2438, 2470, 2485, 2540, 2546]\n"
     ]
    }
   ],
   "source": [
    "f1 = []\n",
    "for i in range(len(s)):\n",
    "    if s['pvalue'][i] < 0.05:\n",
    "        f1.append(s['index'][i])\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "655caaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f[f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2de9ce58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.958\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.955\n",
      "Method:                 Least Squares   F-statistic:                              273.6\n",
      "Date:                Sat, 11 Mar 2023   Prob (F-statistic):                   5.41e-234\n",
      "Time:                        22:21:50   Log-Likelihood:                          88.959\n",
      "No. Observations:                 400   AIC:                                     -115.9\n",
      "Df Residuals:                     369   BIC:                                      7.817\n",
      "Df Model:                          31                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "56            -0.0010      0.000     -2.461      0.014      -0.002      -0.000\n",
      "969            0.0008      0.000      2.352      0.019       0.000       0.002\n",
      "976            0.0010      0.000      2.393      0.017       0.000       0.002\n",
      "1046           0.0003      0.000      0.825      0.410      -0.000       0.001\n",
      "1062          -0.0009      0.000     -2.497      0.013      -0.002      -0.000\n",
      "1069          -0.0006      0.000     -1.773      0.077      -0.001    6.87e-05\n",
      "1167          -0.0009      0.000     -2.520      0.012      -0.002      -0.000\n",
      "1177          -0.0010      0.000     -2.892      0.004      -0.002      -0.000\n",
      "1323           0.0021      0.001      3.822      0.000       0.001       0.003\n",
      "1367           0.0014      0.001      2.653      0.008       0.000       0.002\n",
      "1417           0.0011      0.000      2.214      0.027       0.000       0.002\n",
      "1427           0.0024      0.000      8.519      0.000       0.002       0.003\n",
      "1446          -0.0010      0.000     -2.792      0.006      -0.002      -0.000\n",
      "1681           0.0010      0.000      2.651      0.008       0.000       0.002\n",
      "1730           0.0018      0.000      4.123      0.000       0.001       0.003\n",
      "1789           0.0007      0.001      1.091      0.276      -0.001       0.002\n",
      "1835          -0.0007      0.001     -1.128      0.260      -0.002       0.001\n",
      "1845          -0.0010      0.001     -1.404      0.161      -0.002       0.000\n",
      "1891           0.0017      0.001      2.095      0.037       0.000       0.003\n",
      "1902           0.0010      0.000      2.645      0.009       0.000       0.002\n",
      "1934          -0.0039      0.001     -5.575      0.000      -0.005      -0.003\n",
      "2030          -0.0025      0.001     -4.660      0.000      -0.004      -0.001\n",
      "2073           0.0018      0.001      3.022      0.003       0.001       0.003\n",
      "2116           0.0062      0.001      9.415      0.000       0.005       0.008\n",
      "2274          -0.0026      0.000     -6.421      0.000      -0.003      -0.002\n",
      "2419           0.0012      0.000      2.876      0.004       0.000       0.002\n",
      "2438           0.0012      0.000      2.936      0.004       0.000       0.002\n",
      "2470          -0.0002      0.000     -0.410      0.682      -0.001       0.001\n",
      "2485           0.0010      0.000      2.874      0.004       0.000       0.002\n",
      "2540          -0.0008      0.000     -2.793      0.005      -0.001      -0.000\n",
      "2546          -0.0009      0.000     -2.192      0.029      -0.002   -9.16e-05\n",
      "==============================================================================\n",
      "Omnibus:                       62.764   Durbin-Watson:                   0.949\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              105.467\n",
      "Skew:                          -0.932   Prob(JB):                     1.25e-23\n",
      "Kurtosis:                       4.690   Cond. No.                         70.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#stepwise 2\n",
    "StatsModel = sm.OLS(y, f).fit()\n",
    "print(StatsModel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69e745c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = StatsModel.pvalues\n",
    "s = pd.DataFrame(s)\n",
    "s['pvalue'] = s[0]\n",
    "s = s.reset_index()\n",
    "s = s.drop(0, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "947d54f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56, 969, 976, 1062, 1167, 1177, 1323, 1367, 1417, 1427, 1446, 1681, 1730, 1891, 1902, 1934, 2030, 2073, 2116, 2274, 2419, 2438, 2485, 2540, 2546]\n"
     ]
    }
   ],
   "source": [
    "f2 = []\n",
    "for i in range(len(s)):\n",
    "    if s['pvalue'][i] < 0.05:\n",
    "        f2.append(s['index'][i])\n",
    "print(f2)\n",
    "f = f[f2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c36224d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.957\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.955\n",
      "Method:                 Least Squares   F-statistic:                              337.8\n",
      "Date:                Sat, 11 Mar 2023   Prob (F-statistic):                   6.32e-240\n",
      "Time:                        22:21:53   Log-Likelihood:                          85.080\n",
      "No. Observations:                 400   AIC:                                     -120.2\n",
      "Df Residuals:                     375   BIC:                                     -20.37\n",
      "Df Model:                          25                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "56            -0.0009      0.000     -2.234      0.026      -0.002      -0.000\n",
      "969            0.0008      0.000      2.297      0.022       0.000       0.001\n",
      "976            0.0007      0.000      1.906      0.057   -2.33e-05       0.002\n",
      "1062          -0.0009      0.000     -2.666      0.008      -0.002      -0.000\n",
      "1167          -0.0009      0.000     -2.811      0.005      -0.002      -0.000\n",
      "1177          -0.0012      0.000     -3.448      0.001      -0.002      -0.001\n",
      "1323           0.0021      0.001      3.975      0.000       0.001       0.003\n",
      "1367           0.0014      0.001      2.712      0.007       0.000       0.002\n",
      "1417           0.0010      0.000      2.279      0.023       0.000       0.002\n",
      "1427           0.0024      0.000      8.590      0.000       0.002       0.003\n",
      "1446          -0.0009      0.000     -2.595      0.010      -0.002      -0.000\n",
      "1681           0.0011      0.000      3.064      0.002       0.000       0.002\n",
      "1730           0.0017      0.000      4.200      0.000       0.001       0.003\n",
      "1891           0.0008      0.000      1.697      0.090      -0.000       0.002\n",
      "1902           0.0009      0.000      2.498      0.013       0.000       0.002\n",
      "1934          -0.0040      0.001     -5.776      0.000      -0.005      -0.003\n",
      "2030          -0.0024      0.001     -4.591      0.000      -0.003      -0.001\n",
      "2073           0.0018      0.001      3.078      0.002       0.001       0.003\n",
      "2116           0.0062      0.001      9.652      0.000       0.005       0.007\n",
      "2274          -0.0026      0.000     -6.822      0.000      -0.003      -0.002\n",
      "2419           0.0013      0.000      3.304      0.001       0.001       0.002\n",
      "2438           0.0012      0.000      3.085      0.002       0.000       0.002\n",
      "2485           0.0010      0.000      2.842      0.005       0.000       0.002\n",
      "2540          -0.0009      0.000     -3.085      0.002      -0.001      -0.000\n",
      "2546          -0.0010      0.000     -2.609      0.009      -0.002      -0.000\n",
      "==============================================================================\n",
      "Omnibus:                       58.436   Durbin-Watson:                   0.934\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               92.567\n",
      "Skew:                          -0.903   Prob(JB):                     7.93e-21\n",
      "Kurtosis:                       4.513   Cond. No.                         48.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#stepwise 3\n",
    "StatsModel = sm.OLS(y, f).fit()\n",
    "print(StatsModel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cdecc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = StatsModel.pvalues\n",
    "s = pd.DataFrame(s)\n",
    "s['pvalue'] = s[0]\n",
    "s = s.reset_index()\n",
    "s = s.drop(0, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f0f0d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56, 969, 1062, 1167, 1177, 1323, 1367, 1417, 1427, 1446, 1681, 1730, 1902, 1934, 2030, 2073, 2116, 2274, 2419, 2438, 2485, 2540, 2546]\n"
     ]
    }
   ],
   "source": [
    "f3 = []\n",
    "for i in range(len(s)):\n",
    "    if s['pvalue'][i] < 0.05:\n",
    "        f3.append(s['index'][i])\n",
    "print(f3)\n",
    "f = f[f3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a9bc5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.957\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.954\n",
      "Method:                 Least Squares   F-statistic:                              362.3\n",
      "Date:                Sat, 11 Mar 2023   Prob (F-statistic):                   5.07e-241\n",
      "Time:                        22:21:57   Log-Likelihood:                          81.475\n",
      "No. Observations:                 400   AIC:                                     -117.0\n",
      "Df Residuals:                     377   BIC:                                     -25.15\n",
      "Df Model:                          23                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "56            -0.0009      0.000     -2.223      0.027      -0.002    -9.9e-05\n",
      "969            0.0008      0.000      2.227      0.027    9.08e-05       0.001\n",
      "1062          -0.0007      0.000     -2.048      0.041      -0.001   -2.75e-05\n",
      "1167          -0.0009      0.000     -2.583      0.010      -0.002      -0.000\n",
      "1177          -0.0012      0.000     -3.408      0.001      -0.002      -0.000\n",
      "1323           0.0020      0.001      3.800      0.000       0.001       0.003\n",
      "1367           0.0012      0.001      2.433      0.015       0.000       0.002\n",
      "1417           0.0013      0.000      2.983      0.003       0.000       0.002\n",
      "1427           0.0025      0.000      8.673      0.000       0.002       0.003\n",
      "1446          -0.0007      0.000     -2.094      0.037      -0.001   -4.32e-05\n",
      "1681           0.0012      0.000      3.312      0.001       0.000       0.002\n",
      "1730           0.0018      0.000      4.473      0.000       0.001       0.003\n",
      "1902           0.0011      0.000      3.100      0.002       0.000       0.002\n",
      "1934          -0.0039      0.001     -5.632      0.000      -0.005      -0.003\n",
      "2030          -0.0019      0.000     -5.147      0.000      -0.003      -0.001\n",
      "2073           0.0020      0.001      3.284      0.001       0.001       0.003\n",
      "2116           0.0064      0.001      9.850      0.000       0.005       0.008\n",
      "2274          -0.0026      0.000     -6.629      0.000      -0.003      -0.002\n",
      "2419           0.0012      0.000      2.942      0.003       0.000       0.002\n",
      "2438           0.0013      0.000      3.145      0.002       0.000       0.002\n",
      "2485           0.0009      0.000      2.573      0.010       0.000       0.002\n",
      "2540          -0.0009      0.000     -3.147      0.002      -0.001      -0.000\n",
      "2546          -0.0009      0.000     -2.433      0.015      -0.002      -0.000\n",
      "==============================================================================\n",
      "Omnibus:                       66.995   Durbin-Watson:                   0.925\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              111.137\n",
      "Skew:                          -0.996   Prob(JB):                     7.36e-25\n",
      "Kurtosis:                       4.643   Cond. No.                         45.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#stepwise 4\n",
    "StatsModel = sm.OLS(y, f).fit()\n",
    "print(StatsModel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8c697d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAneklEQVR4nO3df2zc9X3H8dfZae74cT7NTe07K651A8LmmEQKqRNnlJB0thxtFgE0tdCgpN0QZAnCy1BZqCbHGsNJULMyAR4tWwpK2/BHkxarw8NTsFOUWM4vCztmKAOneOUOj5jcGS++CPuzPzLfcrENvvPd5349H9JX7X2/X9+973N3+b74/nh/HcYYIwAAAEsK0l0AAADIL4QPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYtSHcB15qcnNSHH34ot9sth8OR7nIAAMAcGGM0OjqqsrIyFRR8/r6NjAsfH374ocrLy9NdBgAASMDQ0JAWL178uetkXPhwu92SrhRfVFSU5moAAMBchMNhlZeXR7fjnyfjwsfUoZaioiLCBwAAWWYup0xwwikAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAqoxrMgYAs5mYNOoZHNHw6LhK3C5V+4tVWMA9oIBsQ/gAkBXa+wNqbhtQIDQenefzuNTUUKn6Kl8aKwMQLw67AMh47f0BbT1wOiZ4SFIwNK6tB06rvT+QpsoAJILwASCjTUwaNbcNyMywbGpec9uAJiZnWgNAJiJ8AMhoPYMj0/Z4XM1ICoTG1TM4Yq8oAPNC+ACQ0YZHZw8eiawHIP0IHwAyWonbldT1AKQf4QNARqv2F8vncWm2C2odunLVS7W/2GZZAOaB8AEgoxUWONTUUClJ0wLI1OOmhkr6fQBZhPABIOPVV/nUummFvJ7YQytej0utm1bQ5wPIMjQZA5AV6qt8qq300uEUyAGEDwBZo7DAoZqbvpzuMgDME4ddAACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFgVV/hobW3VsmXLVFRUpKKiItXU1Oj111+PLt+yZYscDkfMtHr16qQXDSD7TEwaHX/vgn7V+zsdf++CJiZNuksCkCZxNRlbvHixdu/erZtvvlmS9PLLL+vuu+/WmTNntHTpUklSfX299u/fH/2bhQsXJrFcANmovT+g5rYBBUL/f9t7n8elpoZKWqMDeSiu8NHQ0BDz+O///u/V2tqq7u7uaPhwOp3yer3JqxBAVmvvD2jrgdO6dj9HMDSurQdOc28WIA8lfM7HxMSEDh48qLGxMdXU1ETnd3Z2qqSkREuWLNFDDz2k4eHhpBQKIPtMTBo1tw1MCx6SovOa2wY4BAPkmbjv7dLX16eamhqNj4/rxhtv1OHDh1VZeeV21xs2bNCf/dmfqaKiQoODg/rbv/1brV+/XqdOnZLT6Zzx+SKRiCKRSPRxOBxO8K0AyDQ9gyMxh1quZSQFQuPqGRzhni1AHok7fNx6663q7e3VxYsX9Ytf/EKbN29WV1eXKisr9c1vfjO6XlVVlVauXKmKigr9+te/1r333jvj87W0tKi5uTnxdwAgYw2Pzh48ElkPQG6I+7DLwoULdfPNN2vlypVqaWnR8uXL9eyzz864rs/nU0VFhc6dOzfr8+3cuVOhUCg6DQ0NxVsSgAxV4nYldT0AuSHuPR/XMsbEHDa52oULFzQ0NCSfb/aTyZxO56yHZABkt2p/sXwel4Kh8RnP+3BI8npcqvYX2y4NQBrFtefjySef1G9+8xudP39efX19+v73v6/Ozk59+9vf1qeffqrHH39cx48f1/nz59XZ2amGhgYtWrRI99xzT6rqB5DBCgscamq4ck6Y45plU4+bGipVWHDtUgC5LK49Hx999JEefPBBBQIBeTweLVu2TO3t7aqtrdWlS5fU19enV155RRcvXpTP59O6dev06quvyu12p6p+ABmuvsqn1k0rpvX58NLnA8hbDmNMRl3jFg6H5fF4FAqFVFRUlO5yACTJxKRRz+CIhkfHVeK+cqiFPR5A7ohn+z3vcz4AYC4KCxxcTgtAEjeWAwAAlhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVXGoLIGPQCwTID4QPABmhvT8wrQuqjy6oQE7isAuAtGvvD2jrgdMxwUOSgqFxbT1wWu39gTRVBiAVCB8A0mpi0qi5bWDGu95OzWtuG9DEZEbdCQLAPBA+AKRVz+DItD0eVzOSAqFx9QyO2CsKQEoRPgCk1fDo7MEjkfUAZD7CB4C0KnG7kroegMxH+ACQVtX+Yvk8Ls12Qa1DV656qfYX2ywLQAoRPgCkVWGBQ00NlZI0LYBMPW5qqKTfB5BDCB8A0q6+yqfWTSvk9cQeWvF6XGrdtII+H0COockYgIxQX+VTbaWXDqdAHiB8AMgYhQUO1dz05XSXASDFOOwCAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALAqrvDR2tqqZcuWqaioSEVFRaqpqdHrr78eXW6M0a5du1RWVqbrrrtOd911l86ePZv0ogEAQPaKK3wsXrxYu3fv1smTJ3Xy5EmtX79ed999dzRg7N27V/v27dNzzz2nEydOyOv1qra2VqOjoykpHgAAZB+HMcbM5wmKi4v1zDPP6Lvf/a7KysrU2NioJ554QpIUiURUWlqqPXv26OGHH57T84XDYXk8HoVCIRUVFc2nNAAAYEk82++Ez/mYmJjQwYMHNTY2ppqaGg0ODioYDKquri66jtPp1Nq1a3Xs2LFZnycSiSgcDsdMAAAgd8UdPvr6+nTjjTfK6XTqkUce0eHDh1VZWalgMChJKi0tjVm/tLQ0umwmLS0t8ng80am8vDzekgAAQBaJO3zceuut6u3tVXd3t7Zu3arNmzdrYGAgutzhcMSsb4yZNu9qO3fuVCgUik5DQ0PxlgQAALLIgnj/YOHChbr55pslSStXrtSJEyf07LPPRs/zCAaD8vl80fWHh4en7Q25mtPplNPpjLcMAACQpebd58MYo0gkIr/fL6/Xq46Ojuiyy5cvq6urS2vWrJnvywAAgBwR156PJ598Uhs2bFB5eblGR0d18OBBdXZ2qr29XQ6HQ42NjXr66ad1yy236JZbbtHTTz+t66+/Xg888ECq6gcAAFkmrvDx0Ucf6cEHH1QgEJDH49GyZcvU3t6u2tpaSdL3vvc9Xbp0SX/5l3+pTz75RKtWrdIbb7wht9udkuIBAED2mXefj2SjzwcAANnHSp8PAACARBA+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVcbdXBwCk3sSkUc/giIZHx1XidqnaX6zCgtnvkwVkE8IHAGSY9v6AmtsGFAiNR+f5PC41NVSqvsr3OX8JZAcOuwBABmnvD2jrgdMxwUOSgqFxbT1wWu39gTRVBiQP4QMAMsTEpFFz24Bmajs9Na+5bUATkxnVmBqIG+EDADJEz+DItD0eVzOSAqFx9QyO2CsKSAHCBwBkiOHR2YNHIusBmYrwAQAZosTtSup6QKYifABAhqj2F8vncWm2C2odunLVS7W/2GZZQNIRPgAgQxQWONTUUClJ0wLI1OOmhkr6fSDrET4AaGLS6Ph7F/Sr3t/p+HsXuJoijeqrfGrdtEJeT+yhFa/HpdZNK+jzkcPy6XdIkzEgz9HQKvPUV/lUW+mlw2keybffocMYk1HRKhwOy+PxKBQKqaioKN3lADltqqHVtf8ITG3i+C9tIPVy5XcYz/abwy5AnqKhFZB++fo7JHwAeYqGVkD65evvkPAB5CkaWgHpl6+/Q8IHkKdoaAWkX77+DgkfQJ6ioRWQfvn6OyR8AHmKhlZA+uXr75DwAeQxGloB6ZePv0P6fADQxKShoRWQZtn+O4xn+02HUwAqLHCo5qYvp7sMIK/l0++Qwy4AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIpLbQHAsmzv5wDMV1x7PlpaWvS1r31NbrdbJSUl2rhxo959992YdbZs2SKHwxEzrV69OqlFA0C2au8P6I49R3T/j7v12MFe3f/jbt2x54ja+wPpLg2wJq7w0dXVpW3btqm7u1sdHR367LPPVFdXp7GxsZj16uvrFQgEotO//uu/JrVoAMhG7f0BbT1wWoFQ7O3Rg6FxbT1wmgCCvBHXYZf29vaYx/v371dJSYlOnTqlO++8Mzrf6XTK6/Ump0IAyAETk0bNbQOa6X4WRlduItbcNqDaSi+HYJDz5nXCaSgUkiQVF8fe6rezs1MlJSVasmSJHnroIQ0PD8/6HJFIROFwOGYCgFzTMzgybY/H1YykQGhcPYMj9ooC0iTh8GGM0Y4dO3THHXeoqqoqOn/Dhg366U9/qiNHjugHP/iBTpw4ofXr1ysSicz4PC0tLfJ4PNGpvLw80ZIAIGMNj84ePBJZD8hmCd/Vdtu2bfr1r3+tt956S4sXL551vUAgoIqKCh08eFD33nvvtOWRSCQmmITDYZWXl3NXWwA55fh7F3T/j7u/cL2fP7Q6b24uhtyS8rvaPvroo3rttdd09OjRzw0ekuTz+VRRUaFz587NuNzpdMrpdCZSBgBkjWp/sXwel4Kh8RnP+3BI8nquXHYL5Lq4DrsYY7R9+3YdOnRIR44ckd/v/8K/uXDhgoaGhuTz+RIuEgCyXWGBQ00NlZKuBI2rTT1uaqjkZFPkhbjCx7Zt23TgwAH97Gc/k9vtVjAYVDAY1KVLlyRJn376qR5//HEdP35c58+fV2dnpxoaGrRo0SLdc889KXkDAJAt6qt8at20Ql6PK2a+1+NS66YVqq/iP9KQH+I658PhmDmR79+/X1u2bNGlS5e0ceNGnTlzRhcvXpTP59O6dev0d3/3d3M+kTSeY0YAkI3ocIpcFM/2O+ETTlOF8AEAQPaJZ/vNjeUAAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABg1YJ0FwAAyTQxadQzOKLh0XGVuF2q9hersMCR7rKQ5fheJVdc4aOlpUWHDh3Sf/zHf+i6667TmjVrtGfPHt16663RdYwxam5u1o9+9CN98sknWrVqlZ5//nktXbo06cUDwNXa+wNqbhtQIDQenefzuNTUUKn6Kl8aK0M243uVfHEddunq6tK2bdvU3d2tjo4OffbZZ6qrq9PY2Fh0nb1792rfvn167rnndOLECXm9XtXW1mp0dDTpxQPAlPb+gLYeOB2zgZCkYGhcWw+cVnt/IE2VIZvxvUoNhzHGJPrH//3f/62SkhJ1dXXpzjvvlDFGZWVlamxs1BNPPCFJikQiKi0t1Z49e/Twww9/4XOGw2F5PB6FQiEVFRUlWhqAPDIxaXTHniPTNhBTHJK8HpfeemI9u8oxZ3yv4hPP9nteJ5yGQiFJUnFxsSRpcHBQwWBQdXV10XWcTqfWrl2rY8eOzfgckUhE4XA4ZgKAePQMjsy6gZAkIykQGlfP4Ii9opD1+F6lTsLhwxijHTt26I477lBVVZUkKRgMSpJKS0tj1i0tLY0uu1ZLS4s8Hk90Ki8vT7QkAHlqeHT2DUQi6wES36tUSjh8bN++XW+//bZ+/vOfT1vmcMTufjLGTJs3ZefOnQqFQtFpaGgo0ZIA5KkStyup6wES36tUSih8PProo3rttdf05ptvavHixdH5Xq9Xkqbt5RgeHp62N2SK0+lUUVFRzAQA8aj2F8vncWm2o+4OXbk6odpfbLMsZDm+V6kTV/gwxmj79u06dOiQjhw5Ir/fH7Pc7/fL6/Wqo6MjOu/y5cvq6urSmjVrklMxAFyjsMChpoZKSZq2oZh63NRQyUmBiAvfq9SJK3xs27ZNBw4c0M9+9jO53W4Fg0EFg0FdunRJ0pXDLY2NjXr66ad1+PBh9ff3a8uWLbr++uv1wAMPpOQNAIAk1Vf51Lpphbye2F3gXo9LrZtW0I8BCeF7lRpxXWo723kb+/fv15YtWyT9f5OxF198MabJ2NRJqV+ES20BzAedKJEKfK++WDzb73n1+UgFwgcAANnHWp8PAACAeBE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABg1YJ0FwAg/SYmjXoGRzQ8Oq4St0vV/mIVFjjSXRaAHEX4APJce39AzW0DCoTGo/N8HpeaGipVX+VLY2UAchWHXYA81t4f0NYDp2OChyQFQ+PaeuC02vsDaaoMQC4jfAB5amLSqLltQGaGZVPzmtsGNDE50xoAkDjCB5CnegZHpu3xuJqRFAiNq2dwxF5RAPIC4QPIU8OjswePRNYDgLkifAB5qsTtSup6ADBXhA8gT1X7i+XzuDTbBbUOXbnqpdpfbLMsAHmA8AHkqcICh5oaKiVpWgCZetzUUEm/DwBJR/gA8lh9lU+tm1bI64k9tOL1uNS6aQV9PvLcxKTR8fcu6Fe9v9Px9y5w5VMOyJTPlCZjQJ6rr/KpttJLh1PEoPlc7smkz9RhjMmoKBsOh+XxeBQKhVRUVJTucgAg70w1n7t24zAVR9krln1sfKbxbL857AIAiKL5XO7JxM+U8AEAiKL5XO7JxM+U8AEAiKL5XO7JxM+U8AEAiKL5XO7JxM+U8AEAiKL5XO7JxM+U8AEAiKL5XO7JxM+U8AEAiEHzudyTaZ9p3H0+jh49qmeeeUanTp1SIBDQ4cOHtXHjxujyLVu26OWXX475m1WrVqm7u3tOz0+fDwDIDBOThuZzOSaVn2k82++4O5yOjY1p+fLl+s53vqP77rtvxnXq6+u1f//+6OOFCxfG+zIAgDQrLHCo5qYvp7sMJFGmfKZxh48NGzZow4YNn7uO0+mU1+tNuCgAAJC7UnLOR2dnp0pKSrRkyRI99NBDGh4ennXdSCSicDgcMwEAgNyV9PCxYcMG/fSnP9WRI0f0gx/8QCdOnND69esViURmXL+lpUUejyc6lZeXJ7skAACQQeZ1YzmHwzHthNNrBQIBVVRU6ODBg7r33nunLY9EIjHBJBwOq7y8nBNOAQDIIik94TRePp9PFRUVOnfu3IzLnU6nnE5nqssAAAAZIuV9Pi5cuKChoSH5fFwXDgAAEtjz8emnn+o///M/o48HBwfV29ur4uJiFRcXa9euXbrvvvvk8/l0/vx5Pfnkk1q0aJHuueeepBYOAACyU9zh4+TJk1q3bl308Y4dOyRJmzdvVmtrq/r6+vTKK6/o4sWL8vl8WrdunV599VW53e7kVQ0AALLWvE44TQU6nAIAkH3i2X5zbxcAAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFhF+AAAAFYRPgAAgFWEDwAAYBXhAwAAWEX4AAAAVhE+AACAVYQPAABgFeEDAABYFXf4OHr0qBoaGlRWViaHw6Ff/vKXMcuNMdq1a5fKysp03XXX6a677tLZs2eTVW/CJiaNjr93Qb/q/Z2Ov3dBE5Mm3SUBAGBVpmwLF8T7B2NjY1q+fLm+853v6L777pu2fO/evdq3b59+8pOfaMmSJXrqqadUW1urd999V263OylFx6u9P6DmtgEFQuPReT6PS00Nlaqv8qWlJgAAbMqkbaHDGJNw7HE4HDp8+LA2btwo6cpej7KyMjU2NuqJJ56QJEUiEZWWlmrPnj16+OGHv/A5w+GwPB6PQqGQioqKEi0tqr0/oK0HTuvaN+n4v/9t3bSCAAIAyGk2toXxbL+Tes7H4OCggsGg6urqovOcTqfWrl2rY8eOJfOl5mRi0qi5bWDaYEuKzmtuG+AQDAAgZ2XitjCp4SMYDEqSSktLY+aXlpZGl10rEokoHA7HTMnSMzgSs3vpWkZSIDSunsGRpL0mAACZJBO3hSm52sXhcMQ8NsZMmzelpaVFHo8nOpWXlyetjuHR2Qc7kfUAAMg2mbgtTGr48Hq9kjRtL8fw8PC0vSFTdu7cqVAoFJ2GhoaSVk+J25XU9QAAyDaZuC1Mavjw+/3yer3q6OiIzrt8+bK6urq0Zs2aGf/G6XSqqKgoZkqWan+xfB6XZt7ncuVEG5/HpWp/cdJeEwCATJKJ28K4w8enn36q3t5e9fb2Srpykmlvb68++OADORwONTY26umnn9bhw4fV39+vLVu26Prrr9cDDzyQ7Nq/UGGBQ00NlZI0bdCnHjc1VKqwYLaPBACA7JaJ28K4L7Xt7OzUunXrps3fvHmzfvKTn8gYo+bmZr344ov65JNPtGrVKj3//POqqqqa0/Mn+1JbKbOubQYAIB1SvS2MZ/s9rz4fqZCK8CFdudSoZ3BEw6PjKnFf2b3EHg8AQD5J5bYwnu133B1Os1VhgUM1N3053WUAAJA2mbIt5MZyAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACwivABAACsInwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqxakuwAAQP6amDTqGRzR8Oi4StwuVfuLVVjgSHdZSDHCBwAgLdr7A2puG1AgNB6d5/O41NRQqfoqXxorQ6px2AUAYF17f0BbD5yOCR6SFAyNa+uB02rvD6SpMthA+AAAWDUxadTcNiAzw7Kpec1tA5qYnGkN5ALCBwDAqp7BkWl7PK5mJAVC4+oZHLFXFKwifAAArBoenT14JLIesg/hAwBgVYnbldT1kH0IHwAAq6r9xfJ5XJrtglqHrlz1Uu0vtlkWLCJ8AACsKixwqKmhUpKmBZCpx00NlfT7yGGEDwCAdfVVPrVuWiGvJ/bQitfjUuumFfT5yHFJbzK2a9cuNTc3x8wrLS1VMBhM9ksBALJYfZVPtZVeOpzmoZR0OF26dKn+/d//Pfq4sLAwFS8DAMhyhQUO1dz05XSXActSEj4WLFggr9ebiqcGAABZLiXnfJw7d05lZWXy+/361re+pffff3/WdSORiMLhcMwEAAByV9LDx6pVq/TKK6/o3/7t3/TjH/9YwWBQa9as0YULF2Zcv6WlRR6PJzqVl5cnuyQAAJBBHMaYlDbPHxsb00033aTvfe972rFjx7TlkUhEkUgk+jgcDqu8vFyhUEhFRUWpLA0AACRJOByWx+OZ0/Y7Jed8XO2GG27QbbfdpnPnzs243Ol0yul0proMAACQIVLe5yMSieidd96Rz8c12wAAIAV7Ph5//HE1NDToq1/9qoaHh/XUU08pHA5r8+bNyX4pAP9nYtLQKwFA1kh6+Piv//ov3X///fr444/1la98RatXr1Z3d7cqKiqS/VIAJLX3B9TcNhBzi3Kfx6Wmhkq6RALISCk/4TRe8ZywAuS79v6Ath44rWt/xFP7PGhTDcCWeLbf3NsFyFITk0bNbQPTgoek6LzmtgFNTGbUf18AAOEDyFY9gyMxh1quZSQFQuPqGRyxVxQAzAHhA8hSw6OzB49E1gMAWwgfQJYqcbu+eKU41gMAWwgfQJaq9hfL53FptgtqHbpy1Uu1v9hmWQDwhQgfQJYqLHCoqaFSkqYFkKnHTQ2V9PsAkHEIH0CaTUwaHX/vgn7V+zsdf+9CXFen1Ff51Lpphbye2EMrXo+Ly2yRE+bz+0DmSvm9XQDMLhkNwuqrfKqt9NLhFDmHBnq5iyZjQJrQIAyYHb+P7EOTMSDD0SAMmB2/j9xH+ADSgAZhwOz4feQ+wgeQBjQIA2bH7yP3ET6ANKBBGDA7fh+5j/ABpAENwoDZ8fvIfYQPIA1oEAbMjt9H7iN8AGlCgzBku1Q2AOP3kdvo8wGk2cSkoUEYso6tBmD8PrJHPNtvwgcAIC40AMNMaDIGAEgJGoAhGQgfAIA5owEYkoHwAQCYMxqAIRkIHwCAOaMBGJKB8AEAmDMagCEZCB8AgDmjARiSgfABIKeksvEVrqABWObKlu//gnQXAADJYqvxFa4EkNpKLw3AMkg2ff9pMgYgJ9D4CvksE77/NBkDkFdofIV8lo3ff8IHgKxH4yvks2z8/hM+AGQ9Gl8hn2Xj95/wASDr0fgK+Swbv/+EDwBZj8ZXyGfZ+P0nfADIejS+Qj7Lxu8/4QNATqDxVf7KlsZa8/V57zPbvv8p6/Pxwgsv6JlnnlEgENDSpUv1wx/+UF//+te/8O/o8wFgPiYmDY2v8kg2Ndaaj7m+z3R+/+PZfqckfLz66qt68MEH9cILL+iP/uiP9OKLL+qll17SwMCAvvrVr37u3xI+AABzkQmNtWzIlveZ9iZj+/bt05//+Z/rL/7iL/SHf/iH+uEPf6jy8nK1tram4uUAAHkmGxtrJSJX32fSw8fly5d16tQp1dXVxcyvq6vTsWPHpq0fiUQUDodjJgAAPk82NtZKRK6+z6SHj48//lgTExMqLS2NmV9aWqpgMDht/ZaWFnk8nuhUXl6e7JIAADkmGxtrJSJX32fKrnZxOGJPcDHGTJsnSTt37lQoFIpOQ0NDqSoJAJAjsrGxViJy9X0uSPYTLlq0SIWFhdP2cgwPD0/bGyJJTqdTTqcz2WUAAHLYVGOtYGh8xvMhHLpymWkmNdZKRK6+z6Tv+Vi4cKFuv/12dXR0xMzv6OjQmjVrkv1yAIA8lI2NtRKRq+8zJYddduzYoZdeekn/8i//onfeeUd/9Vd/pQ8++ECPPPJIKl4OAJCHsq2xVqJy8X2mtMnY3r17FQgEVFVVpX/4h3/QnXfe+YV/R58PAEA88qWxXKa/z7Q3GZsPwgcAANkn7U3GAAAAZkP4AAAAVhE+AACAVYQPAABgFeEDAABYRfgAAABWET4AAIBVhA8AAGAV4QMAAFiV9LvaztdUw9VwOJzmSgAAwFxNbbfn0jg948LH6OioJKm8vDzNlQAAgHiNjo7K4/F87joZd2+XyclJffjhh3K73XI44rthTjgcVnl5uYaGhrgvzDwxlsnFeCYPY5lcjGfy5PtYGmM0OjqqsrIyFRR8/lkdGbfno6CgQIsXL57XcxQVFeXlB58KjGVyMZ7Jw1gmF+OZPPk8ll+0x2MKJ5wCAACrCB8AAMCqnAofTqdTTU1Ncjqd6S4l6zGWycV4Jg9jmVyMZ/IwlnOXcSecAgCA3JZTez4AAEDmI3wAAACrCB8AAMAqwgcAALAqZ8LHCy+8IL/fL5fLpdtvv12/+c1v0l1SVjh69KgaGhpUVlYmh8OhX/7ylzHLjTHatWuXysrKdN111+muu+7S2bNn01NshmtpadHXvvY1ud1ulZSUaOPGjXr33Xdj1mE856a1tVXLli2LNmuqqanR66+/Hl3OOCaupaVFDodDjY2N0XmM59zt2rVLDocjZvJ6vdHljOXc5ET4ePXVV9XY2Kjvf//7OnPmjL7+9a9rw4YN+uCDD9JdWsYbGxvT8uXL9dxzz824fO/evdq3b5+ee+45nThxQl6vV7W1tdF78OD/dXV1adu2beru7lZHR4c+++wz1dXVaWxsLLoO4zk3ixcv1u7du3Xy5EmdPHlS69ev19133x39R5xxTMyJEyf0ox/9SMuWLYuZz3jGZ+nSpQoEAtGpr68vuoyxnCOTA6qrq80jjzwSM+8P/uAPzN/8zd+kqaLsJMkcPnw4+nhyctJ4vV6ze/fu6Lzx8XHj8XjMP/3TP6WhwuwyPDxsJJmuri5jDOM5X7/3e79nXnrpJcYxQaOjo+aWW24xHR0dZu3ateaxxx4zxvC9jFdTU5NZvnz5jMsYy7nL+j0fly9f1qlTp1RXVxczv66uTseOHUtTVblhcHBQwWAwZmydTqfWrl3L2M5BKBSSJBUXF0tiPBM1MTGhgwcPamxsTDU1NYxjgrZt26Y/+ZM/0R//8R/HzGc843fu3DmVlZXJ7/frW9/6lt5//31JjGU8Mu7GcvH6+OOPNTExodLS0pj5paWlCgaDaaoqN0yN30xj+9vf/jYdJWUNY4x27NihO+64Q1VVVZIYz3j19fWppqZG4+PjuvHGG3X48GFVVlZG/xFnHOfu4MGDOn36tE6cODFtGd/L+KxatUqvvPKKlixZoo8++khPPfWU1qxZo7NnzzKWccj68DHF4XDEPDbGTJuHxDC28du+fbvefvttvfXWW9OWMZ5zc+utt6q3t1cXL17UL37xC23evFldXV3R5Yzj3AwNDemxxx7TG2+8IZfLNet6jOfcbNiwIfr/b7vtNtXU1Oimm27Syy+/rNWrV0tiLOci6w+7LFq0SIWFhdP2cgwPD09Ln4jP1BncjG18Hn30Ub322mt68803tXjx4uh8xjM+Cxcu1M0336yVK1eqpaVFy5cv17PPPss4xunUqVMaHh7W7bffrgULFmjBggXq6urSP/7jP2rBggXRMWM8E3PDDTfotttu07lz5/huxiHrw8fChQt1++23q6OjI2Z+R0eH1qxZk6aqcoPf75fX640Z28uXL6urq4uxnYExRtu3b9ehQ4d05MgR+f3+mOWM5/wYYxSJRBjHOH3jG99QX1+fent7o9PKlSv17W9/W729vfr93/99xnMeIpGI3nnnHfl8Pr6b8Ujbqa5JdPDgQfOlL33J/PM//7MZGBgwjY2N5oYbbjDnz59Pd2kZb3R01Jw5c8acOXPGSDL79u0zZ86cMb/97W+NMcbs3r3beDwec+jQIdPX12fuv/9+4/P5TDgcTnPlmWfr1q3G4/GYzs5OEwgEotP//M//RNdhPOdm586d5ujRo2ZwcNC8/fbb5sknnzQFBQXmjTfeMMYwjvN19dUuxjCe8fjrv/5r09nZad5//33T3d1t/vRP/9S43e7o9oaxnJucCB/GGPP888+biooKs3DhQrNixYro5Y34fG+++aaRNG3avHmzMebKpWNNTU3G6/Uap9Np7rzzTtPX15feojPUTOMoyezfvz+6DuM5N9/97nejv+evfOUr5hvf+EY0eBjDOM7XteGD8Zy7b37zm8bn85kvfelLpqyszNx7773m7Nmz0eWM5dw4jDEmPftcAABAPsr6cz4AAEB2IXwAAACrCB8AAMAqwgcAALCK8AEAAKwifAAAAKsIHwAAwCrCBwAAsIrwAQAArCJ8AAAAqwgfAADAKsIHAACw6n8BwFwaPrEENsgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = f3\n",
    "xlabel = []\n",
    "ylabel = []\n",
    "for i in features:\n",
    "    xlabel.append(i // 46)\n",
    "    ylabel.append(i % 46)\n",
    "plt.scatter(xlabel, ylabel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "355bf2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>102</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>106</td>\n",
       "      <td>107</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>102</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>105</td>\n",
       "      <td>106</td>\n",
       "      <td>107</td>\n",
       "      <td>108</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>101</td>\n",
       "      <td>102</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>106</td>\n",
       "      <td>107</td>\n",
       "      <td>108</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>101</td>\n",
       "      <td>102</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>105</td>\n",
       "      <td>106</td>\n",
       "      <td>107</td>\n",
       "      <td>108</td>\n",
       "      <td>109</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>101</td>\n",
       "      <td>102</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>105</td>\n",
       "      <td>106</td>\n",
       "      <td>107</td>\n",
       "      <td>108</td>\n",
       "      <td>109</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>105</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1    2    3    4    5    6    7    8    9    10  ...   78   79   80   81  \\\n",
       "61  100  101  102  103  104  105  105  106  107  108  ...  100  100   99   99   \n",
       "60  100  101  102  103  104  105  106  107  108  109  ...  101  101  100  100   \n",
       "59  101  102  103  104  105  105  106  107  108  109  ...  102  101  101  100   \n",
       "58  101  102  103  104  105  106  107  108  109  110  ...  102  102  102  101   \n",
       "57  101  102  103  104  105  106  107  108  109  110  ...  103  102  102  101   \n",
       "..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "5   105  106  106  107  107  108  108  109  109  110  ...   96   96   96   95   \n",
       "4   105  105  106  106  107  107  108  108  109  109  ...   96   96   96   95   \n",
       "3   104  105  105  106  106  107  107  108  108  108  ...   96   96   96   95   \n",
       "2   104  104  105  105  106  106  107  107  107  107  ...   96   96   95   95   \n",
       "1   103  104  104  105  105  106  106  106  107  107  ...   96   95   95   95   \n",
       "\n",
       "     82   83  84  85  86  87  \n",
       "61   99   99  98  98  97  97  \n",
       "60  100   99  99  98  98  97  \n",
       "59  100   99  99  98  98  97  \n",
       "58  100   99  99  99  98  98  \n",
       "57  101  100  99  99  99  98  \n",
       "..  ...  ...  ..  ..  ..  ..  \n",
       "5    95   94  94  94  94  94  \n",
       "4    95   94  94  94  94  94  \n",
       "3    95   94  94  94  94  94  \n",
       "2    95   94  94  94  94  94  \n",
       "1    94   94  94  94  94  94  \n",
       "\n",
       "[61 rows x 87 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = []\n",
    "for i in range(61, 0, -1):\n",
    "    row.append(i)\n",
    "\n",
    "df = pd.read_csv('Volcano.csv', header = None, names = range(1, 88))\n",
    "df.set_axis(row, axis='rows', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56fe4197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0  86  94\n",
       "1  87  94\n",
       "2  86  94\n",
       "3  87  94"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def threebythree(point):\n",
    "    list = []\n",
    "    for x2 in range(max(point[1]-1, 1), min(point[1]+2, 62)):\n",
    "        for x1 in range(max(point[0]-1,1), min(point[0]+2,88)):\n",
    "            list.append([x1, x2, df.loc[x2][x1]])\n",
    "    return pd.DataFrame(list)\n",
    "threebythree([87, 1])\n",
    "\n",
    "def twobytwo(point):\n",
    "    list = []\n",
    "    for x2 in range(max(point[1], 1), min(point[1]+2, 62)):\n",
    "        for x1 in range(max(point[0]-1, 1), min(point[0]+1, 88)):\n",
    "            list.append([x1, df.loc[x2][x1]])\n",
    "    return pd.DataFrame(list)\n",
    "twobytwo([87, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b0ab7352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------ITERATION :  1  --------------------------\n",
      "model intercept : [94.]\n",
      "model coefficients :  [[0. 0.]]\n",
      "Model score :  1.0\n",
      "x1 step :  -1\n",
      "x2 step :  1\n",
      "New x1 :  86\n",
      "New x2 :  2\n",
      "Score :  94\n",
      "---------------------ITERATION :  2  --------------------------\n",
      "model intercept : [94.]\n",
      "model coefficients :  [[0. 0.]]\n",
      "Model score :  1.0\n",
      "x1 step :  -1\n",
      "x2 step :  1\n",
      "New x1 :  85\n",
      "New x2 :  3\n",
      "Score :  94\n",
      "---------------------ITERATION :  3  --------------------------\n",
      "model intercept : [94.]\n",
      "model coefficients :  [[0. 0.]]\n",
      "Model score :  1.0\n",
      "x1 step :  -1\n",
      "x2 step :  1\n",
      "New x1 :  84\n",
      "New x2 :  4\n",
      "Score :  94\n",
      "---------------------ITERATION :  4  --------------------------\n",
      "model intercept : [94.]\n",
      "model coefficients :  [[0. 0.]]\n",
      "Model score :  1.0\n",
      "x1 step :  -1\n",
      "x2 step :  1\n",
      "New x1 :  83\n",
      "New x2 :  5\n",
      "Score :  94\n",
      "---------------------ITERATION :  5  --------------------------\n",
      "model intercept : [135.83333333]\n",
      "model coefficients :  [[-5.00000000e-01 -6.79869978e-17]]\n",
      "Model score :  0.75\n",
      "x1 step :  -2500\n",
      "x2 step :  -212\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  6  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  7  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  8  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  9  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  10  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  11  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  12  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  13  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  14  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  15  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  16  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  17  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  18  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  19  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  20  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  21  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  22  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  23  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  24  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  25  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  26  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  27  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  28  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  29  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  30  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  31  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  32  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  33  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  34  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  35  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  36  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  37  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  38  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  39  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  40  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  41  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  42  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  43  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  44  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  45  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  46  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  47  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  48  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  49  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  50  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  51  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  52  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  53  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  54  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  55  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  56  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  57  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  58  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  59  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  60  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  61  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  62  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  63  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  64  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  65  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  66  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  67  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  68  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  69  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  70  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  71  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  72  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  73  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  74  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  75  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  76  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  77  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  78  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  79  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  80  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  81  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  82  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  83  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  84  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  85  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  86  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  87  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  88  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  89  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  90  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  91  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  92  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  93  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  94  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  95  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  96  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  97  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  98  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  99  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  100  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  101  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  102  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  103  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  104  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  105  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  106  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  107  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  108  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  109  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  110  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  111  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  57\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  112  --------------------------\n",
      "model intercept : [103.]\n",
      "model coefficients :  [[0. 0.]]\n",
      "Model score :  1.0\n",
      "x1 step :  -1\n",
      "x2 step :  1\n",
      "New x1 :  56\n",
      "New x2 :  2\n",
      "Score :  103\n",
      "---------------------ITERATION :  113  --------------------------\n",
      "model intercept : [111.77777778]\n",
      "model coefficients :  [[-0.16666667  0.5       ]]\n",
      "Model score :  0.7500000000000021\n",
      "x1 step :  -833\n",
      "x2 step :  2500\n",
      "New x1 :  1\n",
      "New x2 :  61\n",
      "Score :  100\n",
      "---------------------ITERATION :  114  --------------------------\n",
      "model intercept : [99.]\n",
      "model coefficients :  [[ 1.00000000e+00 -2.77555756e-17]]\n",
      "Model score :  1.0\n",
      "x1 step :  1\n",
      "x2 step :  -86\n",
      "New x1 :  1\n",
      "New x2 :  31\n",
      "Score :  108\n",
      "---------------------ITERATION :  115  --------------------------\n",
      "model intercept : [113.08333333]\n",
      "model coefficients :  [[ 2.33333333 -0.25      ]]\n",
      "Model score :  0.9528301886792461\n",
      "x1 step :  2\n",
      "x2 step :  -1249\n",
      "New x1 :  2\n",
      "New x2 :  1\n",
      "Score :  104\n",
      "---------------------ITERATION :  116  --------------------------\n",
      "model intercept : [102.]\n",
      "model coefficients :  [[0.5        0.66666667]]\n",
      "Model score :  0.8333333333333334\n",
      "x1 step :  2500\n",
      "x2 step :  3333\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  117  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  118  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  119  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  120  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  121  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  122  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  123  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  124  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  125  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  126  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  127  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  128  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  129  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  130  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  131  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  132  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  133  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  134  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  135  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  136  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  137  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  138  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  139  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  140  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  141  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  142  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  143  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  144  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  145  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  146  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  147  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  148  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  149  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  150  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  151  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  152  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  153  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  154  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  155  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  156  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  157  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  158  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  159  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  160  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  161  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  162  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  163  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  164  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  165  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  166  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  167  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  168  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  169  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  170  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  171  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  172  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  173  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  174  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  87\n",
      "New x2 :  61\n",
      "Score :  97\n",
      "---------------------ITERATION :  175  --------------------------\n",
      "model intercept : [170.75]\n",
      "model coefficients :  [[-0.5 -0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  -2500\n",
      "x2 step :  -2499\n",
      "New x1 :  1\n",
      "New x2 :  1\n",
      "Score :  103\n",
      "---------------------ITERATION :  176  --------------------------\n",
      "model intercept : [102.25]\n",
      "model coefficients :  [[0.5 0.5]]\n",
      "Model score :  0.6666666666666667\n",
      "x1 step :  2500\n",
      "x2 step :  2499\n",
      "New x1 :  6\n",
      "New x2 :  61\n",
      "Score :  105\n",
      "---------------------ITERATION :  177  --------------------------\n",
      "model intercept : [120.5]\n",
      "model coefficients :  [[ 0.75       -0.33333333]]\n",
      "Model score :  0.8529411764705858\n",
      "x1 step :  3750\n",
      "x2 step :  -1666\n",
      "New x1 :  87\n",
      "New x2 :  1\n",
      "Score :  94\n",
      "---------------------ITERATION :  178  --------------------------\n",
      "model intercept : [94.]\n",
      "model coefficients :  [[0. 0.]]\n",
      "Model score :  1.0\n",
      "x1 step :  -1\n",
      "x2 step :  1\n",
      "New x1 :  87\n",
      "New x2 :  1\n",
      "Score :  94\n",
      "---------------------ITERATION :  179  --------------------------\n",
      "model intercept : [94.]\n",
      "model coefficients :  [[0. 0.]]\n",
      "Model score :  1.0\n",
      "x1 step :  -1\n",
      "x2 step :  1\n",
      "New x1 :  86\n",
      "New x2 :  2\n",
      "Score :  94\n",
      "---------------------ITERATION :  180  --------------------------\n",
      "model intercept : [94.]\n",
      "model coefficients :  [[0. 0.]]\n",
      "Model score :  1.0\n",
      "x1 step :  -1\n",
      "x2 step :  1\n",
      "New x1 :  86\n",
      "New x2 :  3\n",
      "Score :  94\n",
      "---------------------ITERATION :  181  --------------------------\n",
      "model intercept : [94.]\n",
      "model coefficients :  [[0. 0.]]\n",
      "Model score :  1.0\n",
      "x1 step :  -1\n",
      "x2 step :  1\n",
      "New x1 :  86\n",
      "New x2 :  4\n",
      "Score :  94\n",
      "---------------------ITERATION :  182  --------------------------\n",
      "model intercept : [94.]\n",
      "model coefficients :  [[0. 0.]]\n",
      "Model score :  1.0\n",
      "x1 step :  -1\n",
      "x2 step :  1\n",
      "New x1 :  86\n",
      "New x2 :  5\n",
      "Score :  94\n",
      "---------------------ITERATION :  183  --------------------------\n",
      "model intercept : [94.]\n",
      "model coefficients :  [[0. 0.]]\n",
      "Model score :  1.0\n",
      "x1 step :  -1\n",
      "x2 step :  1\n",
      "New x1 :  85\n",
      "New x2 :  5\n",
      "Score :  94\n",
      "---------------------ITERATION :  184  --------------------------\n",
      "model intercept : [94.]\n",
      "model coefficients :  [[0. 0.]]\n",
      "Model score :  1.0\n",
      "x1 step :  -1\n",
      "x2 step :  1\n",
      "New x1 :  84\n",
      "New x2 :  5\n",
      "Score :  94\n",
      "---------------------ITERATION :  185  --------------------------\n",
      "model intercept : [94.]\n",
      "model coefficients :  [[0. 0.]]\n",
      "Model score :  1.0\n",
      "x1 step :  -1\n",
      "x2 step :  1\n",
      "New x1 :  84\n",
      "New x2 :  6\n",
      "Score :  94\n",
      "---------------------ITERATION :  186  --------------------------\n",
      "model intercept : [107.11111111]\n",
      "model coefficients :  [[-0.16666667  0.16666667]]\n",
      "Model score :  0.375\n",
      "REBULD MODEL!!!!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [70], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m label \u001b[38;5;241m=\u001b[39m smaller_domain\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m     26\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m---> 27\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel intercept :\u001b[39m\u001b[38;5;124m'\u001b[39m, model\u001b[38;5;241m.\u001b[39mintercept_) \u001b[38;5;66;03m# Beta0\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel coefficients : \u001b[39m\u001b[38;5;124m'\u001b[39m, model\u001b[38;5;241m.\u001b[39mcoef_) \u001b[38;5;66;03m# Beta1 ~ Beta2\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:684\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    680\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[1;32m    682\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 684\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[1;32m    689\u001b[0m     sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    690\u001b[0m )\n\u001b[1;32m    692\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m _preprocess_data(\n\u001b[1;32m    693\u001b[0m     X,\n\u001b[1;32m    694\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    698\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    699\u001b[0m )\n",
      "File \u001b[0;32m/Applications/miniconda3/lib/python3.9/site-packages/sklearn/base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    594\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/Applications/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1090\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1071\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1072\u001b[0m     )\n\u001b[1;32m   1074\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1075\u001b[0m     X,\n\u001b[1;32m   1076\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1087\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1088\u001b[0m )\n\u001b[0;32m-> 1090\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1092\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m/Applications/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1100\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[0;32m-> 1100\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1110\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[0;32m/Applications/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:768\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    764\u001b[0m     pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    765\u001b[0m         _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[1;32m    766\u001b[0m     )\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[0;32m--> 768\u001b[0m         dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdtypes_orig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric:\n\u001b[1;32m    771\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dtype_orig\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    772\u001b[0m         \u001b[38;5;66;03m# if input is object, convert to float.\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mresult_type\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "point = [87, 1]\n",
    "iteration = 1\n",
    "highest = 0\n",
    "highest_point = []\n",
    "\n",
    "while iteration <= 5000:\n",
    "    print(\"---------------------ITERATION : \" , iteration , \" --------------------------\")\n",
    "    # using 3x3 at most as domain to build regression model\n",
    "    small_domain = threebythree(point)\n",
    "    features = small_domain.iloc[:, :2]\n",
    "    label = small_domain.iloc[:, 2:]\n",
    "    model = LinearRegression()\n",
    "    model = model.fit(features, label)\n",
    "    print('model intercept :', model.intercept_) # Beta0\n",
    "    print('model coefficients : ', model.coef_) # Beta1 ~ Beta2\n",
    "    print('Model score : ', model.score(features, label)) # R squared\n",
    "    \n",
    "    if model.score(features, label) < 0.5:\n",
    "         # using 2x2 at most as domain to build regression model\n",
    "        print(\"REBULD MODEL!!!!\")\n",
    "        smaller_domain = twobytwo(point)\n",
    "        features = smaller_domain.iloc[:, :2]\n",
    "        label = smaller_domain.iloc[:, 2:]\n",
    "        model = LinearRegression()\n",
    "        model = model.fit(features, label)\n",
    "        print('model intercept :', model.intercept_) # Beta0\n",
    "        print('model coefficients : ', model.coef_) # Beta1 ~ Beta2\n",
    "        print('Model score : ', model.score(features, label)) # R squared\n",
    "        \n",
    "    # compute gradient of x1, x2 to decide next iteration's direction\n",
    "    g_x1 = model.coef_[0][0]\n",
    "    g_x2 = model.coef_[0][1]\n",
    "    \n",
    "    stepx1 = math.floor(abs(g_x1))\n",
    "    stepx2 = math.floor(abs(g_x2))\n",
    "    \n",
    "    # 判斷beta1, beta2正負\n",
    "    signx1 = 0\n",
    "    signx2 = 0\n",
    "    if g_x1 < 0:\n",
    "        signx1 = -1\n",
    "    elif g_x1 > 0:\n",
    "        signx1 = 1\n",
    "    else:\n",
    "        signx1 = 0\n",
    "        \n",
    "    if g_x2 < 0:\n",
    "        signx2 = -1\n",
    "    elif g_x2 >0:\n",
    "        signx2 = 1\n",
    "    else:\n",
    "        signx2 = 0\n",
    "    # 算出這一次iteration走多大步\n",
    "    while stepx1 == 0:\n",
    "        if g_x1 == 0:\n",
    "            break\n",
    "        g_x1 *= 5000\n",
    "        stepx1 = math.floor(abs(g_x1))\n",
    "    stepx1 *= signx1\n",
    "    \n",
    "    while stepx2 == 0:\n",
    "        if g_x2 == 0:\n",
    "            break\n",
    "        g_x2 *= 5000\n",
    "        stepx2 = math.floor(abs(g_x2))\n",
    "    stepx2 *= signx2\n",
    "    \n",
    "    # 如果九宮格都一樣，那就往左上\n",
    "    if stepx1==0 and stepx2 == 0:\n",
    "        stepx1 = -1\n",
    "        stepx2 = 1\n",
    "        \n",
    "    print(\"x1 step : \",stepx1)\n",
    "    print(\"x2 step : \",stepx2)\n",
    "    \n",
    "    if iteration < 100:\n",
    "        newx1 = min(point[0] + stepx1, 87)\n",
    "        newx1 = max(newx1, 1)\n",
    "        newx2 = max(point[1] + stepx2, 1)\n",
    "        newx2 = min(newx2, 61)\n",
    "    else:\n",
    "        newx1 = min(point[0] + round(random.random()*stepx1), 87)\n",
    "        newx1 = max(newx1, 1)\n",
    "        newx2 = max(point[1] + round(random.random()*stepx2), 1)\n",
    "        newx2 = min(newx2, 61)\n",
    "        \n",
    "    print('New x1 : ', newx1) \n",
    "    print('New x2 : ', newx2) \n",
    "    score = df.loc[newx2][newx1]\n",
    "    point = [newx1, newx2]\n",
    "    print('Score : ', score) \n",
    "    if score > highest:\n",
    "        highest = score\n",
    "        highest_point = point\n",
    "    iteration+=1\n",
    "    \n",
    "print(\"Best Point : \",highest_point)\n",
    "print(\"Best Height : \",highest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8526e760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.962\n",
      "Model:                            OLS   Adj. R-squared:                  0.962\n",
      "Method:                 Least Squares   F-statistic:                 6.347e+05\n",
      "Date:                Sat, 11 Mar 2023   Prob (F-statistic):               0.00\n",
      "Time:                        18:23:15   Log-Likelihood:                -70741.\n",
      "No. Observations:               50000   AIC:                         1.415e+05\n",
      "Df Residuals:                   49997   BIC:                         1.415e+05\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         13.0014      0.004   2919.051      0.000      12.993      13.010\n",
      "x1             3.0001      0.004    673.557      0.000       2.991       3.009\n",
      "x2             4.0021      0.004    897.775      0.000       3.993       4.011\n",
      "==============================================================================\n",
      "Omnibus:                        1.138   Durbin-Watson:                   2.013\n",
      "Prob(Omnibus):                  0.566   Jarque-Bera (JB):                1.122\n",
      "Skew:                          -0.009   Prob(JB):                        0.571\n",
      "Kurtosis:                       3.015   Cond. No.                         1.01\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "x1 = np.random.normal(0, 1, 50000)\n",
    "x2 = np.random.normal(0, 1, 50000)\n",
    "\n",
    "# Generate dependent variable\n",
    "y = 13 + 3*x1 + 4*x2 + np.random.normal(0, 1, 50000)\n",
    "\n",
    "# Fit multiple regression model\n",
    "X = sm.add_constant(np.column_stack((x1, x2)))\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a4ffcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [13.0008809   3.000039    4.00194953]\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# Simulate data\n",
    "n = 50000\n",
    "x1 = np.random.normal(0, 1, n)\n",
    "x2 = np.random.normal(0, 1, n)\n",
    "error = np.random.normal(0, 1, n)\n",
    "y = 13 + 3*x1 + 4*x2 + error\n",
    "\n",
    "# Define gradient descent function\n",
    "def gradient_descent(X, y, alpha, num_iters):\n",
    "    m = len(y)\n",
    "    theta = np.zeros(X.shape[1])\n",
    "    error_history = []\n",
    "    theta_history = [theta]\n",
    "    for i in range(num_iters):\n",
    "        predictions = X.dot(theta)\n",
    "        errors = predictions - y\n",
    "        cost = np.sum(errors ** 2) / (2 * m)\n",
    "        error_history.append(cost)\n",
    "        gradient = X.T.dot(errors) / m\n",
    "        theta = theta - alpha * gradient\n",
    "        theta_history.append(theta)\n",
    "    return theta, error_history, theta_history\n",
    "\n",
    "# Fit multiple linear regression model with gradient descent\n",
    "X = np.column_stack((np.ones(n), x1, x2))\n",
    "alpha = 0.01\n",
    "num_iters = 1000\n",
    "theta, error_history, theta_history = gradient_descent(X, y, alpha, num_iters)\n",
    "\n",
    "# Review results\n",
    "print(\"Coefficients:\", theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e045628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
